{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "## Practice Projects\n",
    "# P4: Style Recognition\n",
    "## Step 0. Style and Libraries\n",
    "Let's choose a style of the Jupyter notebook and import the software libraries. \n",
    "\n",
    "The command `hide_code` will display or hide the code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');\n",
    "body {background-color: aliceblue;} \n",
    "a {color: #4876ff; font-family: 'Roboto';} \n",
    "h1 {color: #348ABD; font-family: 'Orbitron'; text-shadow: 4px 4px 4px #ccc;} \n",
    "h2, h3 {color: slategray; font-family: 'Roboto'; text-shadow: 4px 4px 4px #ccc;}\n",
    "h4 {color: #348ABD; font-family: 'Orbitron';}\n",
    "span {text-shadow: 4px 4px 4px #ccc;}\n",
    "div.output_prompt, div.output_area pre {color: slategray;}\n",
    "div.input_prompt, div.output_subarea {color: #4876ff;}      \n",
    "div.output_stderr pre {background-color: aliceblue;}  \n",
    "div.output_stderr {background-color: slategrey;}                        \n",
    "</style>\n",
    "<script>\n",
    "code_show = true; \n",
    "function code_display() {\n",
    "    if (code_show) {\n",
    "        $('div.input').each(function(id) {\n",
    "            if (id == 0 || $(this).html().indexOf('hide_code') > -1) {$(this).hide();}\n",
    "        });\n",
    "        $('div.output_prompt').css('opacity', 0);\n",
    "    } else {\n",
    "        $('div.input').each(function(id) {$(this).show();});\n",
    "        $('div.output_prompt').css('opacity', 1);\n",
    "    };\n",
    "    code_show = !code_show;\n",
    "} \n",
    "$(document).ready(code_display);\n",
    "</script>\n",
    "<form action=\"javascript: code_display()\">\n",
    "<input style=\"color: #348ABD; background: aliceblue; opacity: 0.8;\" \\ \n",
    "type=\"submit\" value=\"Click to display or hide code cells\">\n",
    "</form> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code = ''\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import scipy\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Plot the neural network fitting history\n",
    "def history_plot(fit_history, n):\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.plot(fit_history.history['loss'][n:], color='slategray', label = 'train')\n",
    "    plt.plot(fit_history.history['val_loss'][n:], color='#4876ff', label = 'valid')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title('Loss Function');  \n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt.plot(fit_history.history['acc'][n:], color='slategray', label = 'train')\n",
    "    plt.plot(fit_history.history['val_acc'][n:], color='#4876ff', label = 'valid')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")    \n",
    "    plt.legend()\n",
    "    plt.title('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load and Explore the Data\n",
    "For this project, have made the database of photos sorted by products and brands. \n",
    "\n",
    "The main dataset (style.zip) is 1340 color images (150x150x3) with 7 brands and 10 products, and the file with labels style.csv. \n",
    "\n",
    "Photo files are in the .png format and the labels are integers and values.\n",
    "\n",
    "Run the following cell to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Function for processing an image\n",
    "def image_to_tensor(img_path):\n",
    "    img = keras_image.load_img(\"data/\" + img_path, target_size=(150, 150))\n",
    "    x = keras_image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "# Function for creating the data tensor\n",
    "def data_to_tensor(img_paths):\n",
    "    list_of_tensors = [image_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load and display the data\n",
    "data = pd.read_csv(\"data/style.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize distributions of variables to have an imagination of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# TODO: Plot product distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# TODO: Plot product distribution grouped by brand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the `brand_name` and `product_name` unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print unique values of brand names\n",
    "set(data['brand_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print unique values of product names\n",
    "set(data['product_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create tensors of variables and display some examples of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create tensors\n",
    "brands = data['brand_label'].values\n",
    "products = data['product_label'].values\n",
    "images = data_to_tensor(data['file']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape \n",
    "print ('Image shape:', images.shape)\n",
    "print ('Brand shape', brands.shape)\n",
    "print ('Product shape', products.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read from files and display images using OpenCV\n",
    "def display_images(img_path, ax):\n",
    "    img = cv2.imread(\"data/\" + img_path)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, i + 1, xticks=[], yticks=[], \n",
    "                         title=data['brand_name'][i*110]+' || '+data['product_name'][i*110])\n",
    "    display_images(data['file'][i*110], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Save and Load the Data\n",
    "The data tensors can be saved in the appropriate format of files .h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create the tensor file\n",
    "with h5py.File('StyleColorImages.h5', 'w') as f:\n",
    "    f.create_dataset('images', data = images)\n",
    "    f.create_dataset('brands', data = brands)\n",
    "    f.create_dataset('products', data = products)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next time it is possible to start here with neural network experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read the h5 file\n",
    "f = h5py.File('StyleColorImages.h5', 'r')\n",
    "\n",
    "# List all groups\n",
    "keys = list(f.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create tensors and targets\n",
    "brands = np.array(f[keys[0]])\n",
    "images = np.array(f[keys[1]])\n",
    "products = np.array(f[keys[2]])\n",
    "\n",
    "print ('Image shape:', images.shape)\n",
    "print ('Brand shape', brands.shape)\n",
    "print ('Product shape', products.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Implement Preprocess Functions\n",
    "### Normalize and Gray Scale\n",
    "In the cell below, normalize the image tensors, and return them as a normalized Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Normalize tensors\n",
    "images = images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read and display a tensor using Matplotlib\n",
    "print('Product: ', data['product_name'][500])\n",
    "print('Brand: ', data['brand_name'][500])\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(images[500]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors of grayscaled images and display their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Grayscaled tensors\n",
    "gray_images = np.dot(images[...,:3], [0.299, 0.587, 0.114])\n",
    "print ('Grayscaled Tensor shape:', gray_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read and display a tensor using Matplotlib\n",
    "print('Product: ', data['product_name'][500])\n",
    "print('Brand: ', data['brand_name'][500])\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(gray_images[500], cmap=cm.bone);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encode\n",
    "Now we'll implement the one-hot encoding function to_categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the brand unique values\n",
    "print(set(brands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the product unique values\n",
    "print(set(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# One-hot encode the brands\n",
    "cat_brands = to_categorical(brands, 7)\n",
    "cat_brands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# One-hot encode the products\n",
    "cat_products = to_categorical(products, 10)\n",
    "cat_products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Label Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create multi-label targets\n",
    "targets = np.concatenate((cat_brands, cat_products), axis=1)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split\n",
    "Apply the function train_test_split and split the data into training and testing sets. Set up the size of the testing set - 20%.\n",
    "#### Color Images, Brand Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, cat_brands, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 1)\n",
    "# Divide the test set into test and valid subsets\n",
    "n = int(len(x_test)/2)\n",
    "x_valid, y_valid = x_test[:n], y_test[:n]\n",
    "x_test, y_test = x_test[n:], y_test[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "print (\"Training tensor's shape:\", x_train.shape)\n",
    "print (\"Training target's shape\", y_train.shape)\n",
    "print (\"Validating tensor's shape:\", x_valid.shape)\n",
    "print (\"Validating target's shape\", y_valid.shape)\n",
    "print (\"Testing tensor's shape:\", x_test.shape)\n",
    "print (\"Testing target's shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Images, Product Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the data\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(images, cat_products, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "# Divide the test set into test and valid subsets\n",
    "n = int(len(x_test2)/2)\n",
    "x_valid2, y_valid2 = x_test2[:n], y_test2[:n]\n",
    "x_test2, y_test2 = x_test2[n:], y_test2[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "print (\"Training tensor's shape:\", x_train2.shape)\n",
    "print (\"Training target's shape\", y_train2.shape)\n",
    "print (\"Validating tensor's shape:\", x_valid2.shape)\n",
    "print (\"Validating target's shape\", y_valid2.shape)\n",
    "print (\"Testing tensor's shape:\", x_test2.shape)\n",
    "print (\"Testing target's shape\", y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Images, Multi-Label Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the data\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(images, targets, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "# Divide the test set into test and valid subsets\n",
    "n = int(len(x_test3)/2)\n",
    "x_valid3, y_valid3 = x_test3[:n], y_test3[:n]\n",
    "x_test3, y_test3 = x_test3[n:], y_test3[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "print (\"Training tensor's shape:\", x_train3.shape)\n",
    "print (\"Training target's shape\", y_train3.shape)\n",
    "print (\"Validating tensor's shape:\", x_valid3.shape)\n",
    "print (\"Validating target's shape\", y_valid3.shape)\n",
    "print (\"Testing tensor's shape:\", x_test3.shape)\n",
    "print (\"Testing target's shape\", y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create a list of targets\n",
    "y_train3_list = [y_train3[:, :7], y_train3[:, 7:]]\n",
    "y_test3_list = [y_test3[:, :7], y_test3[:, 7:]]\n",
    "y_valid3_list = [y_valid3[:, :7], y_valid3[:, 7:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscaled Images, Brand Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the data\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(gray_images, cat_brands, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "# Divide the test set into test and valid subsets\n",
    "n = int(len(x_test4)/2)\n",
    "x_valid4, y_valid4 = x_test4[:n], y_test4[:n]\n",
    "x_test4, y_test4 = x_test4[n:], y_test4[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Reshape the grayscaled data\n",
    "x_train4, x_test4, x_valid4 = \\\n",
    "x_train4.reshape(-1, 150, 150, 1), x_test4.reshape(-1, 150, 150, 1), x_valid4.reshape(-1, 150, 150, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "print (\"Training tensor's shape:\", x_train4.shape)\n",
    "print (\"Training target's shape\", y_train4.shape)\n",
    "print (\"Validating tensor's shape:\", x_valid4.shape)\n",
    "print (\"Validating target's shape\", y_valid4.shape)\n",
    "print (\"Testing tensor's shape:\", x_test4.shape)\n",
    "print (\"Testing target's shape\", y_test4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscaled Images, Product Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the data\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(gray_images, cat_products, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "# Divide the test set into test and valid subsets\n",
    "n = int(len(x_test5)/2)\n",
    "x_valid5, y_valid5 = x_test5[:n], y_test5[:n]\n",
    "x_test5, y_test5 = x_test5[n:], y_test5[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Reshape the grayscaled data\n",
    "x_train5, x_test5, x_valid5 = \\\n",
    "x_train5.reshape(-1, 150, 150, 1), x_test5.reshape(-1, 150, 150, 1), x_valid5.reshape(-1, 150, 150, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "print (\"Training tensor's shape:\", x_train5.shape)\n",
    "print (\"Training target's shape\", y_train5.shape)\n",
    "print (\"Validating tensor's shape:\", x_valid5.shape)\n",
    "print (\"Validating target's shape\", y_valid5.shape)\n",
    "print (\"Testing tensor's shape:\", x_test5.shape)\n",
    "print (\"Testing target's shape\", y_test5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscaled Images, Multi-Label Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the data\n",
    "x_train6, x_test6, y_train6, y_test6 = train_test_split(gray_images, targets, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "# Divide the test set into test and valid subsets\n",
    "n = int(len(x_test6)/2)\n",
    "x_valid6, y_valid6 = x_test6[:n], y_test6[:n]\n",
    "x_test6, y_test6 = x_test6[n:], y_test6[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Reshape the grayscaled data\n",
    "x_train6, x_test6, x_valid6 = \\\n",
    "x_train6.reshape(-1, 150, 150, 1), x_test6.reshape(-1, 150, 150, 1), x_valid6.reshape(-1, 150, 150, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "print (\"Training tensor's shape:\", x_train6.shape)\n",
    "print (\"Training target's shape\", y_train6.shape)\n",
    "print (\"Validating tensor's shape:\", x_valid6.shape)\n",
    "print (\"Validating target's shape\", y_valid6.shape)\n",
    "print (\"Testing tensor's shape:\", x_test6.shape)\n",
    "print (\"Testing target's shape\", y_test6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create a list of targets\n",
    "y_train6_list = [y_train6[:, :7], y_train6[:, 7:]]\n",
    "y_test6_list = [y_test6[:, :7], y_test6[:, 7:]]\n",
    "y_valid6_list = [y_valid6[:, :7], y_valid6[:, 7:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Create One-Label Classification Models\n",
    "We should have an accuracy \n",
    "\n",
    "- greater than 14.3% for the first target (`brand`) and \n",
    "\n",
    "- greater than 10% for the second target (`product`).\n",
    "\n",
    "#### Color Images, Brand Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def cb_model():\n",
    "    model = Sequential()\n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "\n",
    "    return model\n",
    "\n",
    "cb_model = cb_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "cb_checkpointer = ModelCheckpoint(filepath='cb_model.styles.hdf5', \n",
    "                                  verbose=2, save_best_only=True)\n",
    "cb_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                    patience=5, verbose=2, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "cb_history = cb_model.fit(x_train, y_train, \n",
    "                          epochs=30, batch_size=16, verbose=2,\n",
    "                          validation_data=(x_valid, y_valid),\n",
    "                          callbacks=[cb_checkpointer,cb_lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the training history\n",
    "history_plot(cb_history, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "cb_model.load_weights('cb_model.styles.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "cb_score = cb_model.evaluate(x_test, y_test)\n",
    "cb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Images, Product Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def cp_model():\n",
    "    model = Sequential()\n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "\n",
    "    # TODO: Compile the model\n",
    "    \n",
    "    return model\n",
    "\n",
    "cp_model = cp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "cp_checkpointer = ModelCheckpoint(filepath='cp_model.styles.hdf5', \n",
    "                                  verbose=2, save_best_only=True)\n",
    "cp_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                    patience=5, verbose=2, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "cp_history = cp_model.fit(x_train2, y_train2, \n",
    "                          epochs=30, batch_size=16, verbose=2,\n",
    "                          validation_data=(x_valid2, y_valid2),\n",
    "                          callbacks=[cp_checkpointer,cp_lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the training history\n",
    "history_plot(cp_history, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "cp_model.load_weights('cp_model.styles.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "cp_score = cp_model.evaluate(x_test2, y_test2)\n",
    "cp_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscaled Images, Brand Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def gray_cb_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "\n",
    "    return model\n",
    "\n",
    "gray_cb_model = gray_cb_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "gray_cb_checkpointer = ModelCheckpoint(filepath='gray_cb_model.styles.hdf5', \n",
    "                                       verbose=2, save_best_only=True)\n",
    "gray_cb_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                         patience=5, verbose=2, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "gray_cb_history = gray_cb_model.fit(x_train4, y_train4, \n",
    "                                    epochs=30, batch_size=16, verbose=2,\n",
    "                                    validation_data=(x_valid4, y_valid4),\n",
    "                                    callbacks=[gray_cb_checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the training history\n",
    "history_plot(gray_cb_history, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "gray_cb_model.load_weights('gray_cb_model.styles.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "gray_cb_score = gray_cb_model.evaluate(x_test4, y_test4)\n",
    "gray_cb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscaled Images, Product Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def gray_cp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "\n",
    "    return model\n",
    "\n",
    "gray_cp_model = gray_cp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "gray_cp_checkpointer = ModelCheckpoint(filepath='gray_cp_model.styles.hdf5', \n",
    "                                       verbose=2, save_best_only=True)\n",
    "gray_cp_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                         patience=5, verbose=2, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "gray_cp_history = gray_cp_model.fit(x_train5, y_train5, \n",
    "                                    epochs=30, batch_size=16, verbose=2,\n",
    "                                    validation_data=(x_valid5, y_valid5),\n",
    "                                    callbacks=[gray_cp_checkpointer,gray_cp_lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the training history\n",
    "history_plot(gray_cp_history, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "gray_cp_model.load_weights('gray_cp_model.styles.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "gray_cp_score = gray_cp_model.evaluate(x_test5, y_test5)\n",
    "gray_cp_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Create Multi-Label Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Color Images, Multi-Label Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def multi_model():    \n",
    "    model_input = Input(shape=(150, 150, 3))\n",
    "    x = BatchNormalization()(model_input)\n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "    \n",
    "    y1 = Dense(7, activation='softmax')(x)\n",
    "    y2 = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=[y1, y2])\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "\n",
    "    return model\n",
    "\n",
    "multi_model = multi_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "multi_checkpointer = ModelCheckpoint(filepath='multi_model.styles.hdf5', \n",
    "                                     verbose=2, save_best_only=True)\n",
    "multi_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                       patience=5, verbose=2, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "multi_history = multi_model.fit(x_train3, y_train3_list, \n",
    "                                validation_data=(x_valid3, y_valid3_list), \n",
    "                                epochs=30, batch_size=16, verbose=0, \n",
    "                                callbacks=[multi_checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "multi_model.load_weights('multi_model.styles.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "multi_scores = multi_model.evaluate(x_test3, y_test3_list, verbose=0)\n",
    "\n",
    "print(\"Scores: \\n\" , (multi_scores))\n",
    "print(\"First label. Accuracy: %.2f%%\" % (multi_scores[3]*100))\n",
    "print(\"Second label. Accuracy: %.2f%%\" % (multi_scores[4]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscaled Images, Multi-Label Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def gray_multi_model():    \n",
    "    model_input = Input(shape=(150, 150, 1))\n",
    "    x = BatchNormalization()(model_input)\n",
    "    # TODO: Define a model architecture\n",
    " \n",
    "    \n",
    "    y1 = Dense(7, activation='softmax')(x)\n",
    "    y2 = Dense(10, activation='softmax')(x)\n",
    "       \n",
    "    model = Model(inputs=model_input, outputs=[y1, y2])\n",
    "    # TODO: Compile the model\n",
    "   \n",
    "    return model\n",
    "\n",
    "gray_multi_model = gray_multi_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "gray_multi_checkpointer = ModelCheckpoint(filepath='gray_multi_model.styles.hdf5', \n",
    "                                          verbose=2, save_best_only=True)\n",
    "gray_multi_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=5, verbose=2, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "gray_multi_history = gray_multi_model.fit(x_train6, y_train6_list, \n",
    "                                          validation_data=(x_valid6, y_valid6_list), \n",
    "                                          epochs=30, batch_size=16, verbose=0, \n",
    "                                          callbacks=[gray_multi_checkpointer,\n",
    "                                                     gray_multi_lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "gray_multi_model.load_weights('gray_multi_model.styles.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "gray_multi_scores = gray_multi_model.evaluate(x_test6, y_test6_list, verbose=0)\n",
    "\n",
    "print(\"Scores: \\n\" , (gray_multi_scores))\n",
    "print(\"First label. Accuracy: %.2f%%\" % (gray_multi_scores[3]*100))\n",
    "print(\"Second label. Accuracy: %.2f%%\" % (gray_multi_scores[4]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
