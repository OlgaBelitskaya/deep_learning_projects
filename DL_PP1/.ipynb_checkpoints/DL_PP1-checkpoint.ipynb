{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "## Practice Projects\n",
    "# P1: Neural Networks for Regression\n",
    "In this project, we'll evaluate the performance and predictive power of neural networks in the sphere of regression tasks. Models will be trained and tested on data collected from homes in suburbs of Boston, Massachusetts.\n",
    "\n",
    "Origin: This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
    "\n",
    "Creators: Harrison, D. and Rubinfeld, D.L.\n",
    "\n",
    "Data Set Information: Concerns housing values in suburbs of Boston.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "- CRIM: per capita crime rate by town\n",
    "- ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS: proportion of non-retail business acres per town\n",
    "- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX: nitric oxides concentration (parts per 10 million)\n",
    "- RM: average number of rooms per dwelling\n",
    "- AGE: proportion of owner-occupied units built prior to 1940\n",
    "- DIS: weighted distances to five Boston employment centres\n",
    "- RAD: index of accessibility to radial highways\n",
    "- TAX: full-value property-tax rate per 10,000 USD\n",
    "- PTRATIO: pupil-teacher ratio by town\n",
    "- B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT: % lower status of the population\n",
    "- MEDV: Median value of owner-occupied homes in 1000 USD\n",
    "\n",
    "The Boston housing data was collected in 1978 and each of the 506 entries represents aggregated data about 14 features for homes from various suburbs.\n",
    "\n",
    "## Step 0. Style and Libraries\n",
    "Let's choose a style of the Jupyter notebook and import the software libraries. The command hide_code will hide the code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');\n",
    "body {background-color: aliceblue;} \n",
    "a {color: #4876ff; font-family: 'Roboto';} \n",
    "h1 {color: #348ABD; font-family: 'Orbitron'; text-shadow: 4px 4px 4px #ccc;} \n",
    "h2, h3 {color: slategray; font-family: 'Roboto'; text-shadow: 4px 4px 4px #ccc;}\n",
    "h4 {color: #348ABD; font-family: 'Orbitron';}\n",
    "span {text-shadow: 4px 4px 4px #ccc;}\n",
    "div.output_prompt, div.output_area pre {color: slategray;}\n",
    "div.input_prompt, div.output_subarea {color: #4876ff;}      \n",
    "div.output_stderr pre {background-color: aliceblue;}  \n",
    "div.output_stderr {background-color: slategrey;}                        \n",
    "</style>\n",
    "<script>\n",
    "code_show = true; \n",
    "function code_display() {\n",
    "    if (code_show) {\n",
    "        $('div.input').each(function(id) {\n",
    "            if (id == 0 || $(this).html().indexOf('hide_code') > -1) {$(this).hide();}\n",
    "        });\n",
    "        $('div.output_prompt').css('opacity', 0);\n",
    "    } else {\n",
    "        $('div.input').each(function(id) {$(this).show();});\n",
    "        $('div.output_prompt').css('opacity', 1);\n",
    "    };\n",
    "    code_show = !code_show;\n",
    "} \n",
    "$(document).ready(code_display);\n",
    "</script>\n",
    "<form action=\"javascript: code_display()\">\n",
    "<input style=\"color: #348ABD; background: aliceblue; opacity: 0.8;\" \\ \n",
    "type=\"submit\" value=\"Click to display or hide code cells\">\n",
    "</form>                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code = ''\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, GlobalAveragePooling1D\n",
    "from keras.layers import Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the Neural network fitting history\n",
    "def history_plot(fit_history, n):\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.plot(fit_history.history['loss'][n:], color='slategray', label = 'train')\n",
    "    plt.plot(fit_history.history['val_loss'][n:], color='#4876ff', label = 'valid')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title('Loss Function');  \n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt.plot(fit_history.history['mean_absolute_error'][n:], color='slategray', label = 'train')\n",
    "    plt.plot(fit_history.history['val_mean_absolute_error'][n:], color='#4876ff', label = 'valid')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MAE\")    \n",
    "    plt.legend()\n",
    "    plt.title('Mean Absolute Error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load and Explore the Data\n",
    "This database is very popular for studying regression and can be downloaded in several ways. Let's display the easiest ones of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the sklearn version\n",
    "boston_data = datasets.load_boston()\n",
    "boston_df = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
    "boston_df['MEDV'] = boston_data.target\n",
    "\n",
    "# Load the keras version\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "# Divide the test set into two subsets.\n",
    "x_valid, y_valid = x_test[:51], y_test[:51]\n",
    "x_test, y_test = x_test[51:], y_test[51:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Display the example of rows\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Display correlation the table\n",
    "pearson = boston_df.corr(method='pearson')\n",
    "corr_with_prices = pearson.iloc[-1][:-1]\n",
    "# TODO: Arrange the variables in descending order of correlation (by absolute values) with the target\n",
    "#       and display the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape of datasets\n",
    "print (\"Training feature's shape:\", x_train.shape)\n",
    "print (\"Training target's shape\", y_train.shape)\n",
    "print (\"Validating feature's shape:\", x_valid.shape)\n",
    "print (\"Validating target's shape\", y_valid.shape)\n",
    "print (\"Testing feature's shape:\", x_test.shape)\n",
    "print (\"Testing target's shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the target distributions\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "plt.subplot(121)\n",
    "sns.distplot(y_train, color='#348ABD', bins=30)\n",
    "plt.ylabel(\"Distribution\")\n",
    "plt.xlabel(\"Prices\")\n",
    "plt.subplot(122)\n",
    "sns.distplot(np.log(y_train), color='#348ABD', bins=30)\n",
    "plt.ylabel(\"Distribution\")\n",
    "plt.xlabel(\"Logarithmic Prices\")\n",
    "plt.suptitle('Boston Housing Data', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Build the Neural Networks\n",
    "### Multilayer Perceptron (MLP)\n",
    "Define a model architecture and compile the model.\n",
    "\n",
    "For more information use the following links:\n",
    "- [Guide to the Sequential model](https://keras.io/getting-started/sequential-model-guide/)\n",
    "- [Convolutional Neural Networks (CNNs / ConvNets)](http://cs231n.github.io/convolutional-networks/)\n",
    "- [Deep Learning Resources](https://sebastianraschka.com/deep-learning-resources.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    # TODO: Create the sequential MLP model  \n",
    "\n",
    "    # TODO: Compile the model    \n",
    "    # model.compile(loss=, optimizer=, metrics=)\n",
    "    return model\n",
    "\n",
    "mlp_model = mlp_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cells below to fit the model and save the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Define parameters\n",
    "# epochs = \n",
    "# batch_size = \n",
    "# Create the checkpointer for saving the best results\n",
    "mlp_checkpointer = ModelCheckpoint(filepath='weights.best.mlp.hdf5', \n",
    "                                   verbose=0, save_best_only=True)\n",
    "# Fit the model\n",
    "mlp_history = mlp_model.fit(x_train, y_train, \n",
    "                            validation_data=(x_valid, y_valid),\n",
    "                            epochs=epochs, batch_size=batch_size, verbose=0, \n",
    "                            callbacks=[mlp_checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fitting history and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Define the starting history point\n",
    "n = 2\n",
    "# Display training history\n",
    "history_plot(mlp_history, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the best model results \n",
    "mlp_model.load_weights('weights.best.mlp.hdf5')\n",
    "# Create predictions\n",
    "y_train_mlp = mlp_model.predict(x_train)\n",
    "y_valid_mlp = mlp_model.predict(x_valid)\n",
    "y_test_mlp = mlp_model.predict(x_test)\n",
    "# Display R2 score\n",
    "score_train_mlp = r2_score(y_train, y_train_mlp)\n",
    "score_valid_mlp = r2_score(y_valid, y_valid_mlp)\n",
    "score_test_mlp = r2_score(y_test, y_test_mlp)\n",
    "print ('Train R2 score:', score_train_mlp)\n",
    "print ('Valid R2 score:', score_valid_mlp)\n",
    "print ('Test R2 score:', score_test_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    # TODO: Create the sequential CNN model        \n",
    "\n",
    "\n",
    "    # TODO: Compile the model    \n",
    "    # model.compile(loss=, optimizer=, metrics=)\n",
    "    return model\n",
    "\n",
    "cnn_model = cnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cells below to fit the model and save the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Define parameters\n",
    "# epochs = \n",
    "# batch_size = \n",
    "# Create the checkpointer for saving the best results\n",
    "cnn_checkpointer = ModelCheckpoint(filepath='weights.best.cnn.hdf5', \n",
    "                                   verbose=0, save_best_only=True)\n",
    "# Fit the model\n",
    "cnn_history = cnn_model.fit(x_train.reshape(-1, 13, 1), y_train, \n",
    "                            validation_data=(x_valid.reshape(-1, 13, 1), y_valid),\n",
    "                            epochs=epochs, batch_size=batch_size, verbose=0, \n",
    "                            callbacks=[cnn_checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fitting history and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Define the starting history point\n",
    "n = 2\n",
    "# Display training history\n",
    "history_plot(cnn_history, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the best model results \n",
    "cnn_model.load_weights('weights.best.cnn.hdf5')\n",
    "# Create predictions\n",
    "y_train_cnn = cnn_model.predict(x_train.reshape(-1, 13, 1))\n",
    "y_valid_cnn = cnn_model.predict(x_valid.reshape(-1, 13, 1))\n",
    "y_test_cnn = cnn_model.predict(x_test.reshape(-1, 13, 1))\n",
    "# Display R2 score\n",
    "score_train_cnn = r2_score(y_train, y_train_cnn)\n",
    "score_valid_cnn = r2_score(y_valid, y_valid_cnn)\n",
    "score_test_cnn = r2_score(y_test, y_test_cnn)\n",
    "print ('Train R2 score:', score_train_cnn)\n",
    "print ('Valid R2 score:', score_valid_cnn)\n",
    "print ('Test R2 score:', score_test_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network (RNN)\n",
    "Define a model architecture and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def rnn_model():\n",
    "    model = Sequential()\n",
    "   # TODO: Create the sequential RNN model  \n",
    "\n",
    "   # TODO: Compile the model\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])    \n",
    "    return model \n",
    "\n",
    "rnn_model = rnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cells below to fit the model and save the best results. Choose parameters for fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Define parameters\n",
    "# epochs = \n",
    "# batch_size = \n",
    "# Create the checkpointer for saving the best results\n",
    "rnn_checkpointer = ModelCheckpoint(filepath='weights.best.rnn.hdf5', \n",
    "                                   verbose=2, save_best_only=True)\n",
    "# Fit the model\n",
    "rnn_history = rnn_model.fit(x_train.reshape(-1, 1, 13), y_train, \n",
    "                            validation_data=(x_valid.reshape(-1, 1, 13), y_valid),\n",
    "                            epochs=epochs, batch_size=batch_size, verbose=0, \n",
    "                            callbacks=[rnn_checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fitting history and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Define the starting history point\n",
    "n = 2\n",
    "# Display training history\n",
    "history_plot(rnn_history, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the best model results \n",
    "rnn_model.load_weights('weights.best.rnn.hdf5')\n",
    "# Create predictions\n",
    "y_train_rnn = rnn_model.predict(x_train.reshape(-1, 1, 13))\n",
    "y_valid_rnn = rnn_model.predict(x_valid.reshape(-1, 1, 13))\n",
    "y_test_rnn = rnn_model.predict(x_test.reshape(-1, 1, 13))\n",
    "# Display R2 score\n",
    "score_train_rnn = r2_score(y_train, y_train_rnn)\n",
    "score_valid_rnn = r2_score(y_valid, y_valid_rnn)\n",
    "score_test_rnn = r2_score(y_test, y_test_rnn)\n",
    "print ('Train R2 score:', score_train_rnn)\n",
    "print ('Valid R2 score:', score_valid_rnn)\n",
    "print ('Test R2 score:', score_test_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Compare Predictions\n",
    "Run the cells below to visualize the quality of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot predicted values and real data points\n",
    "plt.figure(figsize = (18, 6))\n",
    "plt.plot(y_train[:50], color = 'black', label='Real Data')\n",
    "\n",
    "plt.plot(y_train_mlp[:50], label='MLP')\n",
    "plt.plot(y_train_cnn[:50], label='CNN')\n",
    "plt.plot(y_train_rnn[:50], label='RNN')\n",
    "\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Predicted and Real Target Values\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Set; Neural Network Predictions vs Real Data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot predicted values and real data points\n",
    "plt.figure(figsize = (18, 6))\n",
    "plt.plot(y_valid, color = 'black', label='Real Data')\n",
    "\n",
    "plt.plot(y_valid_mlp, label='MLP')\n",
    "plt.plot(y_valid_cnn, label='CNN')\n",
    "plt.plot(y_valid_rnn, label='RNN')\n",
    "\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Predicted and Real Target Values\")\n",
    "plt.legend()\n",
    "plt.title(\"Validating Set; Neural Network Predictions vs Real Data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot predicted values and real data points\n",
    "plt.figure(figsize = (18, 6))\n",
    "plt.plot(y_test, color = 'black', label='Real Data')\n",
    "\n",
    "plt.plot(y_test_mlp, label='MLP')\n",
    "plt.plot(y_test_cnn, label='CNN')\n",
    "plt.plot(y_test_rnn, label='RNN')\n",
    "\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Predicted and Real Target Values\")\n",
    "plt.legend()\n",
    "plt.title(\"Testing Set; Neural Network Predictions vs Real Data\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
