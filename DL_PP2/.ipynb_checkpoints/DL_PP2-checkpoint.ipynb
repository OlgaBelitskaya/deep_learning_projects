{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "## Practice Projects\n",
    "# P2: Multi-Label Classification\n",
    "\n",
    "## Step 0. Style and Libraries\n",
    "Let's choose a style of the Jupyter notebook and import the software libraries. The command hide_code will hide the code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');\n",
    "body {background-color: aliceblue;} \n",
    "a {color: #4876ff; font-family: 'Roboto';} \n",
    "h1 {color: #348ABD; font-family: 'Orbitron'; text-shadow: 4px 4px 4px #ccc;} \n",
    "h2, h3 {color: slategray; font-family: 'Roboto'; text-shadow: 4px 4px 4px #ccc;}\n",
    "h4 {color: #348ABD; font-family: 'Orbitron';}\n",
    "span {text-shadow: 4px 4px 4px #ccc;}\n",
    "div.output_prompt, div.output_area pre {color: slategray;}\n",
    "div.input_prompt, div.output_subarea {color: #4876ff;}      \n",
    "div.output_stderr pre {background-color: aliceblue;}  \n",
    "div.output_stderr {background-color: slategrey;}                        \n",
    "</style>\n",
    "<script>\n",
    "code_show = true; \n",
    "function code_display() {\n",
    "    if (code_show) {\n",
    "        $('div.input').each(function(id) {\n",
    "            if (id == 0 || $(this).html().indexOf('hide_code') > -1) {$(this).hide();}\n",
    "        });\n",
    "        $('div.output_prompt').css('opacity', 0);\n",
    "    } else {\n",
    "        $('div.input').each(function(id) {$(this).show();});\n",
    "        $('div.output_prompt').css('opacity', 1);\n",
    "    };\n",
    "    code_show = !code_show;\n",
    "} \n",
    "$(document).ready(code_display);\n",
    "</script>\n",
    "<form action=\"javascript: code_display()\">\n",
    "<input style=\"color: #348ABD; background: aliceblue; opacity: 0.8;\" \\ \n",
    "type=\"submit\" value=\"Click to display or hide code cells\">\n",
    "</form>                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code = ''\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import scipy\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the Neural network fitting history\n",
    "def history_plot(fit_history, n):\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.plot(fit_history.history['loss'][n:], color='slategray', label = 'train')\n",
    "    plt.plot(fit_history.history['val_loss'][n:], color='#4876ff', label = 'valid')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title('Loss Function');  \n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt.plot(fit_history.history['acc'][n:], color='slategray', label = 'train')\n",
    "    plt.plot(fit_history.history['val_acc'][n:], color='#4876ff', label = 'valid')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")    \n",
    "    plt.legend()\n",
    "    plt.title('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load and Explore the Data\n",
    "For this project, I have created the dataset of 1650 (50x33) color images (32x32x3) with 33 handwritten letters.\n",
    "\n",
    "\n",
    "Run the following cell to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Function for processing an image\n",
    "def image_to_tensor(img_path):\n",
    "    img = keras_image.load_img(\"data/\" + img_path, target_size=(32, 32))\n",
    "    x = keras_image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "# Function for creating the data tensor\n",
    "def data_to_tensor(img_paths):\n",
    "    list_of_tensors = [image_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "# Load the data\n",
    "data = pd.read_csv(\"data/letters.csv\")\n",
    "files = data['file']\n",
    "letters = data['letter']\n",
    "backgrounds = data['background']\n",
    "targets = data['label'].values\n",
    "tensors = data_to_tensor(files);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape \n",
    "print ('Tensor shape:', tensors.shape)\n",
    "print ('Target shape', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read from files and display images using OpenCV\n",
    "def display_images(img_path, ax):\n",
    "    img = cv2.imread(\"data/\" + img_path)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "for i in range(12):\n",
    "    ax = fig.add_subplot(2, 6, i + 1, xticks=[], yticks=[], title=letters[i*50])\n",
    "    display_images(files[i*50], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Save and Load the Data\n",
    "The data tensors can be saved in the appropriate format of files .h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create the tensor file\n",
    "with h5py.File('LetterColorImages.h5', 'w') as f:\n",
    "    f.create_dataset('images', data = tensors)\n",
    "    f.create_dataset('labels', data = targets)\n",
    "    f.create_dataset('backgrounds', data = backgrounds)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read the h5 file\n",
    "f = h5py.File('LetterColorImages.h5', 'r')\n",
    "\n",
    "# List all groups\n",
    "keys = list(f.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create tensors and targets\n",
    "tensors = np.array(f[keys[1]])\n",
    "targets = np.array(f[keys[2]])\n",
    "print ('Tensor shape:', tensors.shape)\n",
    "print ('Target shape', targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Implement Preprocess Functions\n",
    "### Normalize and Gray Scale\n",
    "In the cell below, normalize the image tensors, and return them as a normalized Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Normalize the tensors\n",
    "tensors = tensors.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read and display a tensor using Matplotlib\n",
    "print('Label: ', letters[100])\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(tensors[100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors of grayscaled images and display their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Grayscaled tensors\n",
    "gray_tensors = np.dot(tensors[...,:3], [0.299, 0.587, 0.114])\n",
    "print ('Grayscaled Tensor shape:', gray_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Read and display a grayscaled tensor using Matplotlib\n",
    "print('Label: ', letters[100])\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(gray_tensors[100], cmap=cm.bone);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Now we'll implement the one-hot encoding function to_categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the target unique values\n",
    "print(set(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# One-hot encode the targets, started from the zero label\n",
    "cat_targets = to_categorical(np.array(targets-1), 33)\n",
    "cat_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# One-hot encode the background targets\n",
    "backgrounds = to_categorical(backgrounds, 2)\n",
    "backgrounds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create multi-label targets\n",
    "back_targets = np.concatenate((cat_targets, backgrounds), axis=1)\n",
    "back_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split\n",
    "#### Color Images\n",
    "Apply the function train_test_split and split the data into training and testing sets. \n",
    "\n",
    "Set up the size for the test set - 10% and for the validation set - 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(tensors, cat_targets, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 1)\n",
    "n = int(len(x_test)/2)\n",
    "x_valid, y_valid = x_test[:n], y_test[:n]\n",
    "x_test, y_test = x_test[n:], y_test[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the grayscaled data\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(gray_tensors, cat_targets, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "x_valid2, y_valid2 = x_test2[:n], y_test2[:n]\n",
    "x_test2, y_test2 = x_test2[n:], y_test2[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Reshape the grayscaled data\n",
    "x_train2, x_test2, x_valid2 = \\\n",
    "x_train2.reshape(-1, 32, 32, 1), x_test2.reshape(-1, 32, 32, 1), x_valid2.reshape(-1, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "x_train2.shape, x_valid2.shape, x_test2.shape, y_train2.shape, y_valid2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Convert images from grayscaled to RGB\n",
    "x_train2_tensor = tf.image.grayscale_to_rgb(x_train2, name=None)\n",
    "x_test2_tensor = tf.image.grayscale_to_rgb(x_test2, name=None)\n",
    "x_valid2_tensor = tf.image.grayscale_to_rgb(x_valid2, name=None)\n",
    "# Run tensorflow session\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    x_train2_color = x_train2_tensor.eval()\n",
    "    x_test2_color = x_test2_tensor.eval()\n",
    "    x_valid2_color = x_valid2_tensor.eval()\n",
    "# Check the shape    \n",
    "x_train2_color.shape, x_test2_color.shape, x_valid2_color.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-label targets, color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split with multi-label targets\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(tensors, back_targets, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "x_valid3, y_valid3 = x_test3[:n], y_test3[:n]\n",
    "x_test3, y_test3 = x_test3[n:], y_test3[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "x_train3.shape, x_valid3.shape, x_test3.shape, y_train3.shape, y_valid3.shape, y_test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create a list of targets\n",
    "y_train3_list = [y_train3[:, :33], y_train3[:, 33:]]\n",
    "y_test3_list = [y_test3[:, :33], y_valid3[:, 33:]]\n",
    "y_valid3_list = [y_valid3[:, :33], y_valid3[:, 33:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-label targets, grayscaled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Split the grayscaled data\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(gray_tensors, back_targets, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "x_valid4, y_valid4 = x_test4[:n], y_test4[:n]\n",
    "x_test4, y_test4 = x_test4[n:], y_test4[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Reshape the grayscaled data\n",
    "x_train4, x_test4, x_valid4 = \\\n",
    "x_train4.reshape(-1, 32, 32, 1), x_test4.reshape(-1, 32, 32, 1), x_valid4.reshape(-1, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Print the shape\n",
    "x_train4.shape, x_valid4.shape, x_test4.shape, y_train4.shape, y_valid4.shape, y_test4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create a list of targets\n",
    "y_train4_list = [y_train4[:, :33], y_train4[:, 33:]]\n",
    "y_test4_list = [y_test4[:, :33], y_test4[:, 33:]]\n",
    "y_valid4_list = [y_valid4[:, :33], y_valid4[:, 33:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Create a One-Label Classification Model\n",
    "### Color Images\n",
    "Define a model architecture and compile the model for color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.model.hdf5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                 patience=5, verbose=2, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=100, batch_size=64, verbose=2,\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    callbacks=[checkpointer, lr_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have an accuracy greater than 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "model.load_weights('weights.best.model.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "score = model.evaluate(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the ImageDataGenerator() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the model with ImageDataGenerator()\n",
    "# TODO: Define parameters\n",
    "# steps, epochs = , \n",
    "data_generator = ImageDataGenerator(zoom_range=0.2, shear_range=0.2, rotation_range=20)\n",
    "\n",
    "generator = model.fit_generator(data_generator.flow(x_train, y_train, batch_size=64),\n",
    "                                steps_per_epoch = steps, epochs = epochs,\n",
    "                                validation_data = (x_valid, y_valid), \n",
    "                                callbacks=[checkpointer, lr_reduction], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "model.load_weights('weights.best.model.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "score = model.evaluate(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results with classifying algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the classifier and get the accuracy score\n",
    "y_train_c = np.array([np.argmax(y) for y in y_train])\n",
    "y_test_c = np.array([np.argmax(y) for y in y_test])\n",
    "clf = GradientBoostingClassifier().fit(x_train.reshape(-1, 32*32*3), y_train_c)\n",
    "clf.score(x_test.reshape(-1, 32*32*3), y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the classifier and get the accuracy score\n",
    "clf2 = RandomForestClassifier().fit(x_train.reshape(-1, 32*32*3), y_train_c)\n",
    "clf2.score(x_test.reshape(-1, 32*32*3), y_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def gray_model():\n",
    "    model = Sequential()\n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "    \n",
    "    return model\n",
    "\n",
    "gray_model = gray_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "gray_checkpointer = ModelCheckpoint(filepath='weights.best.gray_model.hdf5', \n",
    "                                    verbose=2, save_best_only=True)\n",
    "gray_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                      patience=10, verbose=2, factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "gray_history = gray_model.fit(x_train2, y_train2, \n",
    "                              epochs=200, batch_size=64, verbose=0,\n",
    "                              validation_data=(x_valid2, y_valid2),\n",
    "                              callbacks=[gray_checkpointer, gray_lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the training history\n",
    "history_plot(gray_history, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to reach an accuracy greater than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "gray_model.load_weights('weights.best.gray_model.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "gray_score = gray_model.evaluate(x_test2, y_test2)\n",
    "gray_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the ImageDataGenerator() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the model with ImageDataGenerator()\n",
    "# TODO: Define parameters\n",
    "steps, epochs = , \n",
    "data_generator = ImageDataGenerator(zoom_range=0.2, shear_range=0.2, rotation_range=20)\n",
    "\n",
    "gray_generator = gray_model.fit_generator(data_generator.flow(x_train2, y_train2, batch_size=64),\n",
    "                                          steps_per_epoch = steps, epochs = epochs,\n",
    "                                          validation_data = (x_valid2, y_valid2), \n",
    "                                          callbacks=[gray_checkpointer, gray_lr_reduction], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "gray_model.load_weights('weights.best.gray_model.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "gray_score = gray_model.evaluate(x_test2, y_test2)\n",
    "gray_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results with classifying algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the classifier and get the accuracy score\n",
    "y_train2_c = np.array([np.argmax(y) for y in y_train2])\n",
    "y_test2_c = np.array([np.argmax(y) for y in y_test2])\n",
    "clf = GradientBoostingClassifier().fit(x_train2.reshape(-1, 32*32), y_train2_c)\n",
    "clf.score(x_test2.reshape(-1, 32*32), y_test2_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the classifier and get the accuracy score\n",
    "clf2 = RandomForestClassifier().fit(x_train2.reshape(-1, 32*32), y_train2_c)\n",
    "clf2.score(x_test2.reshape(-1, 32*32), y_test2_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Create a Multi-Label Classification Model\n",
    "### Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def multi_model():    \n",
    "    model_input = Input(shape=(32, 32, 3))\n",
    "    x = BatchNormalization()(model_input)\n",
    "    # TODO: Define a model architecture\n",
    "        \n",
    "    \n",
    "    y1 = Dense(33, activation='softmax')(x)\n",
    "    y2 = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=[y1, y2])\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "\n",
    "    return model\n",
    "\n",
    "multi_model = multi_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Display the model architecture\n",
    "multi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "multi_checkpointer = ModelCheckpoint(filepath='weights.best.multi.hdf5', \n",
    "                                     verbose=2, save_best_only=True)\n",
    "multi_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                       patience=5, verbose=2, factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "multi_history = multi_model.fit(x_train3, y_train3_list, \n",
    "                                validation_data=(x_valid3, y_valid3_list), \n",
    "                                epochs=100, batch_size=64, verbose=0, \n",
    "                                callbacks=[multi_checkpointer, multi_lr_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have an accuracy greater than 3% for the first target (letter) and greater than 50% for the second target (background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "multi_model.load_weights('weights.best.multi.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "multi_scores = multi_model.evaluate(x_test3, y_test3_list, verbose=0)\n",
    "\n",
    "print(\"Scores: \\n\" , (multi_scores))\n",
    "print(\"First label. Accuracy: %.2f%%\" % (multi_scores[3]*100))\n",
    "print(\"Second label. Accuracy: %.2f%%\" % (multi_scores[4]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Grayscaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def gray_multi_model():    \n",
    "    model_input = Input(shape=(32, 32, 1))\n",
    "    x = BatchNormalization()(model_input)\n",
    "    # TODO: Define a model architecture\n",
    "    \n",
    "    y1 = Dense(33, activation='softmax')(x)\n",
    "    y2 = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "   \n",
    "    model = Model(inputs=model_input, outputs=[y1, y2])\n",
    "    # TODO: Compile the model\n",
    "    return model\n",
    "\n",
    "gray_multi_model = gray_multi_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Display the model architecture\n",
    "gray_multi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "gray_multi_checkpointer = ModelCheckpoint(filepath='weights.best.gray_multi.hdf5', \n",
    "                                          verbose=2, save_best_only=True)\n",
    "gray_multi_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, verbose=2, factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Train the model\n",
    "gray_multi_history = gray_multi_model.fit(x_train4, y_train4_list, \n",
    "                                          validation_data=(x_valid4, y_valid4_list), \n",
    "                                          epochs=100, batch_size=64, verbose=0, \n",
    "                                          callbacks=[gray_multi_checkpointer, gray_multi_lr_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have an accuracy greater than 3% for the first target (letter) and greater than 50% for the second target (background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "gray_multi_model.load_weights('weights.best.gray_multi.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "gray_multi_scores = gray_multi_model.evaluate(x_test4, y_test4_list, verbose=0)\n",
    "\n",
    "print(\"Scores: \\n\" , (gray_multi_scores))\n",
    "print(\"First label. Accuracy: %.2f%%\" % (gray_multi_scores[3]*100))\n",
    "print(\"Second label. Accuracy: %.2f%%\" % (gray_multi_scores[4]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Keras Applications\n",
    "Choose one of the keras applications and try to reach an accuracy greater than 30%\n",
    "### Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create bottleneck features\n",
    "resize_x_train = np.array([scipy.misc.imresize(x_train[i], (139, 139, 3)) \n",
    "                           for i in range(0, len(x_train))]).astype('float32')\n",
    "resize_x_valid = np.array([scipy.misc.imresize(x_valid[i], (139, 139, 3)) \n",
    "                           for i in range(0, len(x_valid))]).astype('float32')\n",
    "resize_x_test = np.array([scipy.misc.imresize(x_test[i], (139, 139, 3)) \n",
    "                          for i in range(0, len(x_test))]).astype('float32')\n",
    "\n",
    "iv3_x_train = preprocess_input(resize_x_train)\n",
    "iv3_x_valid = preprocess_input(resize_x_valid)\n",
    "iv3_x_test = preprocess_input(resize_x_test)\n",
    "\n",
    "iv3_base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x_train_bn = iv3_base_model.predict(iv3_x_train)\n",
    "x_valid_bn = iv3_base_model.predict(iv3_x_valid)\n",
    "x_test_bn = iv3_base_model.predict(iv3_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Save bottleneck features\n",
    "x_train_bn = np.squeeze(x_train_bn)\n",
    "x_valid_bn = np.squeeze(x_valid_bn)\n",
    "x_test_bn = np.squeeze(x_test_bn)\n",
    "\n",
    "np.save('x_train_bn.npy', x_train_bn)\n",
    "np.save('x_valid_bn.npy', x_valid_bn)\n",
    "np.save('x_test_bn.npy', x_test_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load bottleneck features\n",
    "x_train_bn = np.load('x_train_bn.npy')\n",
    "x_valid_bn = np.load('x_valid_bn.npy')\n",
    "x_test_bn = np.load('x_test_bn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def iv3_model():\n",
    "    model = Sequential()\n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "    # TODO: Compile the model     \n",
    "\n",
    "    return model\n",
    "\n",
    "iv3_model = iv3_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "iv3_checkpointer = ModelCheckpoint(filepath='weights.best.iv3.hdf5', \n",
    "                                     verbose=2, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the model \n",
    "iv3_history = iv3_model.fit(x_train_bn, y_train, \n",
    "                            validation_data=(x_valid_bn, y_valid),\n",
    "                            epochs=50, batch_size=64, \n",
    "                            callbacks=[iv3_checkpointer], verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the training history\n",
    "history_plot(iv3_history, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "iv3_model.load_weights('weights.best.iv3.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "iv3_scores = iv3_model.evaluate(x_test_bn, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (iv3_scores[1]*100))\n",
    "iv3_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create bottleneck features\n",
    "resize_x_train2 = np.array([scipy.misc.imresize(x_train2_color[i], (139, 139, 3)) \n",
    "                            for i in range(0, len(x_train2_color))]).astype('float32')\n",
    "resize_x_valid2 = np.array([scipy.misc.imresize(x_valid2_color[i], (139, 139, 3)) \n",
    "                            for i in range(0, len(x_valid2_color))]).astype('float32')\n",
    "resize_x_test2 = np.array([scipy.misc.imresize(x_test2_color[i], (139, 139, 3)) \n",
    "                           for i in range(0, len(x_test2_color))]).astype('float32')\n",
    "\n",
    "iv3_x_train2 = preprocess_input(resize_x_train2)\n",
    "iv3_x_valid2 = preprocess_input(resize_x_valid2)\n",
    "iv3_x_test2 = preprocess_input(resize_x_test2)\n",
    "\n",
    "iv3_base_model2 = InceptionV3(weights='imagenet', include_top=False)\n",
    "x_train_bn2 = iv3_base_model2.predict(iv3_x_train2)\n",
    "x_valid_bn2 = iv3_base_model2.predict(iv3_x_valid2)\n",
    "x_test_bn2 = iv3_base_model2.predict(iv3_x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Save bottleneck features\n",
    "x_train_bn2 = np.squeeze(x_train_bn2)\n",
    "x_valid_bn2 = np.squeeze(x_valid_bn2)\n",
    "x_test_bn2 = np.squeeze(x_test_bn2)\n",
    "\n",
    "np.save('x_train_bn2.npy', x_train_bn2)\n",
    "np.save('x_valid_bn2.npy', x_valid_bn2)\n",
    "np.save('x_test_bn2.npy', x_test_bn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load bottleneck features\n",
    "x_train_bn2 = np.load('x_train_bn2.npy')\n",
    "x_valid_bn2 = np.load('x_valid_bn2.npy')\n",
    "x_test_bn2 = np.load('x_test_bn2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "def iv3_gray_model():\n",
    "    model = Sequential()\n",
    "    # TODO: Define a model architecture\n",
    "\n",
    "    # TODO: Compile the model     \n",
    "\n",
    "    return model\n",
    "\n",
    "iv3_gray_model = iv3_gray_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create callbacks\n",
    "iv3_gray_checkpointer = ModelCheckpoint(filepath='weights.best.iv3_gray.hdf5', \n",
    "                                        verbose=2, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Fit the model \n",
    "iv3_gray_history = iv3_gray_model.fit(x_train_bn2, y_train2, \n",
    "                                      validation_data=(x_valid_bn2, y_valid2),\n",
    "                                      epochs=50, batch_size=64, \n",
    "                                      callbacks=[iv3_gray_checkpointer], verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Plot the training history\n",
    "history_plot(iv3_gray_history, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Load the model with the best validation accuracy\n",
    "iv3_gray_model.load_weights('weights.best.iv3_gray.hdf5')\n",
    "# Calculate classification accuracy on the testing set\n",
    "iv3_gray_scores = iv3_gray_model.evaluate(x_test_bn2, y_test2)\n",
    "print(\"Accuracy: %.2f%%\" % (iv3_gray_scores[1]*100))\n",
    "iv3_gray_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Predictions\n",
    "Display predictions for the models with the best accuracy.\n",
    "### Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Create a list of symbols\n",
    "symbols = ['а','б','в','г','д','е','ё','ж','з','и','й',\n",
    "           'к','л','м','н','о','п','р','с','т','у','ф',\n",
    "           'х','ц','ч','ш','щ','ъ','ы','ь','э','ю','я']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Model predictions for the testing dataset\n",
    "y_test_predict = iv3_model.predict_classes(x_test_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Display true labels and predictions\n",
    "fig = plt.figure(figsize=(18, 18))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = y_test_predict[idx]\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(symbols[pred_idx], symbols[true_idx]),\n",
    "                 color=(\"#4876ff\" if pred_idx == true_idx else \"darkred\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Model predictions for the testing dataset\n",
    "y_test2_predict = gray_model.predict_classes(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# Display true labels and predictions\n",
    "fig = plt.figure(figsize=(18, 18))\n",
    "for i, idx in enumerate(np.random.choice(x_test2.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test2[idx]), cmap=cm.bone)\n",
    "    pred_idx = y_test2_predict[idx]\n",
    "    true_idx = np.argmax(y_test2[idx])\n",
    "    ax.set_title(\"{} ({})\".format(symbols[pred_idx], symbols[true_idx]),\n",
    "                 color=(\"#4876ff\" if pred_idx == true_idx else \"darkred\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
